{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbe7d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re, os, time\n",
    "from glob import glob\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import json, pyperclip as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a26bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=[\"a-returners-magic-should-be-special\",\n",
    "       \"survival-story-of-a-sword-king-in-a-fantasy-world\",\n",
    "       \"omniscient-readers-viewpoint\",\n",
    "       \"the-beginning-after-the-end\",\n",
    "       \"seoul-station-druid\",\n",
    "       \"reincarnated-into-a-warlock-66666-years-later\",\n",
    "       \"tower-of-god\",\n",
    "       \"the-gamer\",\n",
    "       \"the-tutorial-towers-advanced-player\",\n",
    "       \"infinite-level-up-in-murim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021199d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping a-returners-magic-should-be-special...\n",
      "Scraping survival-story-of-a-sword-king-in-a-fantasy-world...\n",
      "Downloading chapter 0...\n",
      "Downloading chapter 5...\n",
      "Downloading chapter 10...\n",
      "Downloading chapter 15...\n",
      "Downloading chapter 20...\n",
      "Downloading chapter 25...\n",
      "Downloading chapter 30...\n",
      "Downloading chapter 35...\n",
      "Downloading chapter 40...\n",
      "Downloading chapter 45...\n",
      "Downloading chapter 50...\n",
      "Downloading chapter 55...\n",
      "Downloading chapter 60...\n",
      "Downloading chapter 65...\n",
      "Downloading chapter 70...\n",
      "Downloading chapter 75...\n",
      "Downloading chapter 80...\n",
      "Downloading chapter 85...\n",
      "Downloading chapter 90...\n",
      "Downloading chapter 95...\n",
      "Downloading chapter 100...\n",
      "Downloading chapter 105...\n",
      "Downloading chapter 110...\n",
      "Downloading chapter 115...\n",
      "Downloading chapter 120...\n",
      "Downloading chapter 125...\n",
      "Downloading chapter 130...\n",
      "Downloading chapter 135...\n",
      "Downloading chapter 140...\n",
      "Downloading chapter 145...\n",
      "Scraping omniscient-readers-viewpoint...\n",
      "Downloading chapter 0...\n",
      "Downloading chapter 5...\n",
      "Downloading chapter 10...\n",
      "Downloading chapter 15...\n",
      "Downloading chapter 20...\n",
      "Downloading chapter 25...\n"
     ]
    }
   ],
   "source": [
    "for title in titles:\n",
    "    if os.path.exists(f\"{title}.json\"):\n",
    "        GIST = json.load(open(f\"{title}.json\",\"r\"))\n",
    "        page = int(max(GIST['chapters'].keys(),key=int))+1\n",
    "    else:\n",
    "        GIST={}\n",
    "        GIST['title']=title\n",
    "        GIST['description']=''\n",
    "        GIST['artist']=\"\"\n",
    "        GIST['author']=''\n",
    "        GIST['cover']=''\n",
    "        GIST['chapters']={}        \n",
    "        page=0\n",
    "\n",
    "    failure_counter = 0\n",
    "\n",
    "    new_image_urls = {}\n",
    "    print(f\"Scraping {title}...\")\n",
    "    while True:\n",
    "        if page%5 == 0:\n",
    "            print(f\"Downloading chapter {page}...\")\n",
    "\n",
    "        res = requests.get(f\"https://mangaonlineteam.com/manga/{title}/chapter-{page}/\")    \n",
    "        s = str(res.content)\n",
    "        searchers = re.findall(\"image-[0-9]+\",s)\n",
    "        if len(searchers)==0:\n",
    "            failure_counter += 1\n",
    "\n",
    "        if failure_counter == 3:\n",
    "            break\n",
    "        elif len(searchers)==0:\n",
    "            page+=1\n",
    "            continue\n",
    "        else:\n",
    "            failure_counter = 0\n",
    "\n",
    "        for i in searchers:\n",
    "            url = 'http'+s[s.find(i):].split('http')[1].split('\\\"')[0]\n",
    "            L = new_image_urls.get(page,[])\n",
    "            L.append(url)\n",
    "            new_image_urls[page]=L\n",
    "        page+=1\n",
    "        \n",
    "    ti = int(time.time())\n",
    "    for i in new_image_urls:\n",
    "        GIST['chapters'][str(i)] = {\n",
    "            \"title\": str(i),\n",
    "            \"volume\": \"1\",\n",
    "            \"last_updated\": str(ti),\n",
    "            \"groups\": {\n",
    "                \"1\": new_image_urls[i]\n",
    "            }\n",
    "        }\n",
    "        ti-=1    \n",
    "    json.dump(GIST,open(f'{title}.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f005ffa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash update_git.sh"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88a63dce",
   "metadata": {},
   "source": [
    "raw = f\"https://raw.githubusercontent.com/atarashansky2/MangaReader/master/{title}.json\"\n",
    "cp.copy(raw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
